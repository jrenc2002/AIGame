import { generateText, streamText, CoreMessage } from 'ai'
import { createOpenAI } from '@ai-sdk/openai'
import { getAPIConfig, getValidAPIKey, hasValidAPIConfig } from '../apiConfig'

// AIå“åº”ç»“æœæ¥å£
export interface AIResponse {
  content: string
  confidence: number
  reasoning?: string
  metadata?: Record<string, any>
}

// AIæµå¼å“åº”æ¥å£
export interface AIStreamResponse {
  content: string
  isComplete: boolean
  delta?: string
}

// AIé…ç½®æ¥å£
export interface AIServiceConfig {
  provider: 'openai'
  model: string
  maxTokens: number
  temperature: number
  timeout: number
}

// åŸºç¡€AIæœåŠ¡ç±»
export abstract class BaseAIService {
  protected config: AIServiceConfig

  constructor(config?: Partial<AIServiceConfig>) {
    // å…ˆä½¿ç”¨ä¸æŠ›å‡ºé”™è¯¯çš„æ–¹å¼è·å–é…ç½®
    const apiConfig = getAPIConfig(false)
    
    this.config = {
      provider: 'openai',
      model: apiConfig.openaiModel || 'gpt-4o-mini',
      maxTokens: apiConfig.maxTokens || 2000,
      temperature: apiConfig.temperature || 0.7,
      timeout: 30000,
      ...config
    }
    
    // å»¶è¿ŸéªŒè¯é…ç½® - åªæœ‰åœ¨å®é™…ä½¿ç”¨æ—¶æ‰éªŒè¯
    console.log('ğŸš€ AIæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆå»¶è¿ŸéªŒè¯é…ç½®ï¼‰')
  }

  /**
   * éªŒè¯AIé…ç½®æ˜¯å¦æœ‰æ•ˆ - å¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯
   */
  protected validateConfiguration(): void {
    try {
      hasValidAPIConfig('openai')
      getValidAPIKey('openai')
      console.log('âœ… AIæœåŠ¡é…ç½®éªŒè¯æˆåŠŸ')
    } catch (error) {
      console.error('âŒ AIæœåŠ¡é…ç½®éªŒè¯å¤±è´¥:', error)
      throw new Error(`AIæœåŠ¡é…ç½®æ— æ•ˆ: ${error instanceof Error ? error.message : 'unknown error'}`)
    }
  }

  /**
   * è·å–AIæ¨¡å‹å®ä¾‹ - åœ¨è¿™é‡ŒéªŒè¯é…ç½®
   */
  protected getModel() {
    // æ¯æ¬¡ä½¿ç”¨æ—¶éªŒè¯é…ç½®
    this.validateConfiguration()
    
    const apiKey = getValidAPIKey('openai')
    const apiConfig = getAPIConfig()
    
    // åˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹
    const openaiClient = createOpenAI({
      apiKey: apiKey,
      baseURL: apiConfig.openaiBaseUrl || 'https://api.openai-next.com/v1'
    })

    // è¿”å›æŒ‡å®šæ¨¡å‹
    return openaiClient(this.config.model)
  }

  /**
   * éæµå¼AIè°ƒç”¨ - å¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯
   */
  async generateResponse(messages: CoreMessage[]): Promise<AIResponse> {
    try {
      console.log(`ğŸ¤– AIè°ƒç”¨å¼€å§‹ - æ¨¡å‹: ${this.config.model}`)
      const model = this.getModel()
      const result = await generateText({
        model,
        messages,
        maxTokens: this.config.maxTokens,
        temperature: this.config.temperature,
      })

      console.log(`âœ… AIè°ƒç”¨æˆåŠŸ - å“åº”é•¿åº¦: ${result.text.length}`)
      return {
        content: result.text,
        confidence: this.calculateConfidence(result.text),
        metadata: {
          finishReason: result.finishReason,
          usage: result.usage,
          model: this.config.model,
          isRealAI: true
        }
      }
    } catch (error) {
      console.error('âŒ AIç”Ÿæˆå¤±è´¥:', error)
      throw new Error(`AIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'unknown error'}`)
    }
  }

  /**
   * æµå¼AIè°ƒç”¨ - å¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºé”™è¯¯
   */
  async *generateStreamResponse(
    messages: CoreMessage[]
  ): AsyncGenerator<AIStreamResponse, void, unknown> {
    try {
      console.log(`ğŸ¤– AIæµå¼è°ƒç”¨å¼€å§‹ - æ¨¡å‹: ${this.config.model}`)
      const model = this.getModel()
      const stream = await streamText({
        model,
        messages,
        maxTokens: this.config.maxTokens,
        temperature: this.config.temperature,
      })

      let content = ''
      
      for await (const delta of stream.textStream) {
        content += delta
        yield {
          content,
          isComplete: false,
          delta
        }
      }

      // æœ€ç»ˆå“åº”
      console.log(`âœ… AIæµå¼è°ƒç”¨æˆåŠŸ - æ€»é•¿åº¦: ${content.length}`)
      yield {
        content,
        isComplete: true
      }
      
    } catch (error) {
      console.error('âŒ AIæµå¼ç”Ÿæˆå¤±è´¥:', error)
      throw new Error(`AIæµå¼è°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'unknown error'}`)
    }
  }

  /**
   * è®¡ç®—å“åº”å¯ä¿¡åº¦ï¼ˆç®€å•å®ç°ï¼‰
   */
  protected calculateConfidence(text: string): number {
    // åŸºäºæ–‡æœ¬é•¿åº¦å’Œå…³é”®è¯å¯†åº¦è®¡ç®—å¯ä¿¡åº¦
    const length = text.length
    const hasReasoningKeywords = /å› ä¸º|æ‰€ä»¥|åˆ†æ|åˆ¤æ–­|æ¨ç†/.test(text)
    const hasUncertainty = /å¯èƒ½|æˆ–è®¸|ä¸ç¡®å®š|å¤§æ¦‚/.test(text)
    
    let confidence = 0.7 // åŸºç¡€å¯ä¿¡åº¦
    
    if (length > 20 && length < 200) confidence += 0.1
    if (hasReasoningKeywords) confidence += 0.1
    if (hasUncertainty) confidence -= 0.1
    
    return Math.max(0.1, Math.min(1.0, confidence))
  }

  /**
   * æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨
   */
  async isAvailable(): Promise<boolean> {
    try {
      await this.generateResponse([
        { role: 'user', content: 'æµ‹è¯•è¿æ¥' }
      ])
      return true
    } catch {
      return false
    }
  }

  /**
   * åˆ·æ–°é…ç½®
   */
  refreshConfiguration(): void {
    this.validateConfiguration()
  }
} 